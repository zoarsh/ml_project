# -*- coding: utf-8 -*-
"""BIU ML 001 - Data Preperation _Solution.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hkASAaN4-d7A9NfstUNBcHLRIun_y6YV
"""

# Commented out IPython magic to ensure Python compatibility.
#!pip install pandas
import pandas as pd
#!pip install numpy
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")
# %matplotlib inline

"""# DATA PREP

### 1. Uploading the data
"""

df1=pd.read_csv(r"C:\Users\ophir\OneDrive\Desktop\BIU\Class 1\income_1.csv",index_col=0)
df2=pd.read_csv(r"C:\Users\ophir\OneDrive\Desktop\BIU\Class 1\income_2.csv",index_col=0)

"""### 2. Merging tables
Inner Join                                                                                                                        
This type of merge returns only the rows where there is a match between the two dataframes.<br>                                      
Outer Join      <br>                                                                                                              This type of merge returns all rows from both dataframes, and fills in NaN where there are no matches.
"""

# Merge the dataframes on common columns without duplicating columns
merged_df= pd.merge(df1, df2, on=['age', 'workclass', 'fnlwgt'], how='inner')

# Save the merged dataframe to a new CSV file
merged_df.to_csv('merged_income.csv', index=False)

# Display the first few rows of the merged dataframe
merged_df

merged_df.columns

"""### 3. Convert an objects into viable data
(string, int, float....)
"""

df=merged_df.copy()

df.info()

df['income']=df['income'].astype('string')

# We can replace df['income'] values to avoid risk of changing the values in other columns
df=df.replace(to_replace="<=50K", value="0")
df=df.replace(to_replace=">50K", value="1")

"""### 4. Value counts of 50>"""

df['income'].value_counts()

#Values of the categorial feature
df['education'].value_counts()

df['education']=df['education'].astype('string')
df['education']=df['education'].str.replace('-','')

df.info()

"""### 5. Clean Text - remove punctuation"""

#!pip install string
import string

# Columns to convert
columns_to_convert = ['workclass', 'education', 'relationship', 'sex', 'race','occupation','native.country']

# Convert specified columns to string type and create string_df
string_df = df[columns_to_convert].astype('string')

# Convert specified columns to string type and create string_df
string_df = df[columns_to_convert].astype(str)

# Remove punctuation in one line
string_df = string_df.applymap(lambda x: x.translate(str.maketrans('', '', string.punctuation)))

# Assign the cleaned columns back to the original DataFrame
df[columns_to_convert] = string_df

# Display the resulting DataFrame
df

"""exploring features"""

df['race'].value_counts()
#df['workclass'].value_counts()
#df['relationship'].value_counts()

"""### 6. Narrowing Categories

Exploriring the 'native.country' category
"""

df['native.country'].value_counts()

#North America
df['native.country'] = df['native.country'].replace({'UnitedStates': "North America",
                                                     'Mexico': "North America",
                                                     'Canada': "North America",
                                                     'Puerto Rico': "North America",
                                                     'Cuba': "North America",
                                                     'Jamaica': "North America",
                                                     'DominicanRepublic':"North America",
                                                     'Nicaragua':"North America",
                                                     'Honduras':"North America",
                                                     'OutlyingUSGuamUSVIet':"North America",
                                                     'PuertoRico':"North America"
                                                    })

#South America
df['native.country'] = df['native.country'].replace({
                                                     'Columbia':"Central and South America",
                                                     'Peru':"Central and South America",
                                                     'Ecuador':"Central and South America",
                                                     'Guatemala':"Central and South America",
                                                     'Nicaragua':"Central and South America",
                                                     'ElSalvador': "Central and South America",
                                                     'Haiti': "Central and South America",
                                                     'Central America': "Central and South America",
                                                     'TrinadadTobago':"Central and South America"})

# Create a dictionary for replacement (map)
replacement_dict = {'England': 'UK', 'Scotland': 'UK', 'Ireland': 'UK'}

# Use the map function to replace values in 'native.country' based on the dictionary
# The fillna function ensures that any values not in the dictionary remain unchanged
df['native.country'] = df['native.country'].map(replacement_dict).fillna(df['native.country'])

#Europe
df['native.country'] = df['native.country'].replace({'Italy': "Europe",
                                                     'Poland': "Europe",
                                                     'Germany': "Europe",
                                                     'Portugal': "Europe",
                                                     'Hungary': "Europe",
                                                     'Greece': "Europe",
                                                     'Yugoslavia': "Europe",
                                                     'France': "Europe",
                                                     'HolandNetherlands': "Europe"})

#Asia
df['native.country'] = df['native.country'].replace({'Philippines': "Asia",
                                                     'India': "Asia",  'China': "Asia",
                                                     'Philippines': "Asia",
                                                     'China': "Asia",
                                                     'Japan': "Asia",
                                                     'Taiwan': "Asia",
                                                     'Iran': "Asia",
                                                     'Hong': "Asia",
                                                     'Laos': "Asia",
                                                     'South': "Asia",
                                                     'Vietnam': "Asia",
                                                     'Cambodia': "Asia",
                                                     'Thailand': "Asia"})

df['native.country'].value_counts()

df.info()

df['income'].value_counts()

df.info()

"""Changing values"""

df=df.replace(to_replace="Female", value='1')
df=df.replace(to_replace="Male", value='0')

df['sex']=df['sex'].astype(int)

df['sex'].value_counts()

df.info()

df['age'].value_counts()#reduce

"""#### Task

1-Create age groups <br> 2- Crate a countplot for the groups

### Age Groups
"""

# Categorize the ages into bins with labels
df['age_range'] = pd.cut(df['age'], bins=[0, 18, 24, 34, 44, 69, float('inf')], labels=['<18', '18-24', '25-34', '35-44', '45-69', '>70'], right=False)

# Aggregate the age groups
age_group_aggregation = df.groupby('age_range').size().reset_index(name='count')

age_group_aggregation

# Create a countplot
plt.figure(figsize=(10, 6))
sns.countplot(x='age_range', data=df, order=['<18', '18-24', '25-34', '35-44', '45-69', '>70'])
plt.title('Count of Age Groups')
plt.xlabel('Age Range')
plt.ylabel('Count')
plt.show()

df['sex'].value_counts()

df_dummy=df['income']

sns.countplot(df_dummy)

"""Saving Manipulated data"""

df.to_csv('final_income_copy')

"""Another option is Pickle file

# Pickle file

A pickle file in Python is used to serialize and deserialize Python objects. <br>Serialization (write binary) is the process of converting a Python object into a byte stream, which can then be written to a file or transmitted over a network. <br>Deserialization (read binary) is the reverse process, converting the byte stream back into a Python object.
"""

df.to_pickle('mrg_df_after_data_prep_5.2.25.pkl')
df=pd.read_pickle('mrg_df_after_data_prep_5.2.25.pkl')

import pickle
#Write a pickle file
with open('income.pkl', 'wb') as f:
    pickle.dump(df, f)

print("income dataset saved as a pickle file.")

#Read a pickle file and load the data
with open('income.pkl', 'rb') as file:
    loaded_data = pickle.load(file)

loaded_data

"""# We got A flat file, Next to EDA"""



