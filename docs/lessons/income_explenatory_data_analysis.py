# -*- coding: utf-8 -*-
"""Income - Explenatory Data Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n9A3zrXBIU3Ee62aEHGX4hvabWV8ZV1F

# EDA - Explenatory Data Analysis
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
import warnings
warnings.filterwarnings("ignore")
import pickle

df=pd.read_csv(r'C:\Users\ophir\OneDrive\Desktop\BIU\Class 2\income_v2.csv', index_col=0)

df.info()

df['income'].value_counts()

df.info()

df

"""# DATA PROTOCOL

Reporting types Missing, min, max
"""

with pd.ExcelWriter("summary.xlsx") as xw:
    df.dtypes.astype(str).rename("dtype").to_excel(xw, sheet_name="data_type")
    df.max(numeric_only=True).to_excel(xw, sheet_name="max_numeric")
    df.min(numeric_only=True).to_excel(xw, sheet_name="min_numeric")
    df.isnull().sum().rename("missing").to_excel(xw, sheet_name="missing")
    df.nunique().rename("unique").to_excel(xw, sheet_name="unique")

"""# descriptive statistics"""

# Commented out IPython magic to ensure Python compatibility.
from autoviz.AutoViz_Class import AutoViz_Class
# %matplotlib inline
AV = AutoViz_Class()
AV.AutoViz(r'C:\Users\ophir\OneDrive\Desktop\BIU\Class 2\income_v2.csv')

"""# dummies"""

#creating df_dummy
df_dummy=df['sex']
df_dummy

fig, ax=plt.subplots(figsize=(20, 5))
sns.countplot(x=df['sex'].dropna(),data=df)

"""# Categorials"""

new_df=['workclass', 'age', 'education', 'education.num','marital.status','occupation', 'relationship','race','native.country']
df_cat= df[new_df]

df_cat.info()

a=3 #number of rows
b=3 #number of columns
c=1 #plot counter

fig=plt.figure(figsize=(50,40))
plt.subplots_adjust(hspace = 0.8)
sns.set(font_scale = 2)
for i in df_cat:

    plt.subplot(a,b,c)
    plt.title('{}'.format(i))
    plt.xlabel(i)
    sns.countplot(df_cat[i])
    c=c+1

plt.show()

df['age']=df['age'].astype(float)

"""# Continues (numeric)"""

#get all numeric data
#cols=df.columns
df_num=df._get_numeric_data().dropna()
df_num.shape

df_num.info()

# Convert specified columns to float
columns_to_convert = ['fnlwgt', 'education.num', 'age','hours.per.week', 'capital.loss']
df_num = df[columns_to_convert].astype(float)

df_num.hist(figsize=(35, 35), bins=35, xlabelsize=8, ylabelsize=8, color = "cornflowerblue");

"""# Skewness"""

def highlight(cell_value):
    highlight = 'background-color: mediumspringgreen;'
    default = ''
    negative = 'background-color: hotpink;'
    if cell_value > 1:
        return highlight
    elif cell_value < -1:
        return negative
    #else
       # return default
pd.DataFrame(df_num.skew(),columns=['skewness']).sort_values(by='skewness', ascending=False).style.applymap(highlight)

"""# Y - Target Value"""

fig, ax=plt.subplots(figsize=(20, 5))
sns.countplot(x=df['income'].dropna(),data=df)

df['income'].value_counts()

# Convert 'income' column to a binary variable
df['income'] = (df['income'] == '>50K').astype(int)

"""### Correlation"""

df.info()

"""# Label Encoding"""

from sklearn.preprocessing import LabelEncoder

# Identify object (categorical) columns
categorical_cols = df.select_dtypes(include=['object', 'category']).columns

# Initialize LabelEncoder
le = LabelEncoder()

# Apply Label Encoding to each categorical column
for col in categorical_cols:
    df[col] = le.fit_transform(df[col])

df.info()

df.corr(method='spearman')

sns.heatmap(df.corr())

"""# T-Test"""

import scipy.stats as stats
import seaborn as sns

df['sex'].value_counts()

"""# Chis-quare"""

df_cat.columns

import pandas as pd
from scipy.stats import chi2_contingency

# Select specified columns
selected_columns = ['workclass', 'education', 'education.num', 'marital.status',
                    'occupation', 'relationship', 'race', 'native.country']
df_chi = df[selected_columns]
df_chi=df_chi.dropna()

# Select two categorical columns for Chi-Square testing (e.g., 'education' vs 'marital.status')
contingency_table = pd.crosstab(df_chi['education'], df_chi['marital.status'])
#Select two categorical columns for Chi-Square testing (e.g., 'education' vs 'marital.status')
# Perform the Chi-Square test
chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)

# Print results
print("\nChi-Square Test Results:")
print(f"Chi-Square Statistic: {chi2_stat:.4f}")
print(f"P-Value: {p_value:.4f}")
print(f"Degrees of Freedom: {dof}")

"""# Missing"""

df.isnull().head()

sns.heatmap(df.isnull(), yticklabels=False, cbar=False)

"""### Outliers"""

plt.figure(figsize=(20,200))

def outliers_boxplot(df_num):
    for i, col in enumerate(df_num.columns):
        if col != 'income':
            ax = plt.subplot(60, 3, i+1)
            sns.boxplot(data=df_num, x=col, ax=ax)
            plt.subplots_adjust(hspace = 0.7)
            plt.title('Box Plot: {}'.format(col), fontsize=15)
            plt.xlabel('{}'.format(col), fontsize=14)

outliers_boxplot(df_num)

"""### OUTLIERS DF

"""

from scipy import stats
z = np.abs(stats.zscore(df_num['capital.loss']))
print(z)

df_num.corr()

# Calculate correlations with outliers
correlation_with_outliers = df_num.corr()
# Calculate correlations with outliers
outlier_threshold = 2.5  # Adjust as needed

sns.heatmap(correlation_with_outliers)

df_num['capital.loss'].value_counts()

df_num

# Initialize a list to store outliers that change either correlation or distribution
outliers_change_corr_or_dist = []

# Iterate through each column and find outliers that change correlation or distribution
for column in df_num.columns:
    if column == "income":
        continue

    # Find indices of outliers
    outlier_indices = np.where(np.abs(stats.zscore(df_num[column])) > outlier_threshold)

    # Calculate correlation without the outliers
    df_no_outliers = df_num.drop(index=outlier_indices[0])
    correlation_without_outliers = df_no_outliers.corr()

    # Compare correlations and check if distribution changes
    if not np.allclose(correlation_with_outliers, correlation_without_outliers, rtol=0.05) or not np.array_equal(correlation_with_outliers, correlation_without_outliers):
        outliers_change_corr_or_dist.extend(outlier_indices[0])

# Remove duplicates from the list
outliers_change_corr_or_dist = list(set(outliers_change_corr_or_dist))

# Print the outliers that change either correlation or distribution
#print("Outliers changing either correlation or distribution:", outliers_change_corr_or_dist)

# Remove outliers changing either correlation or distribution from the DataFrame
df_filtered = df.drop(index=outliers_change_corr_or_dist)

#if there were any unnacesary outliers, they are now cleaned

"""## Missing"""

#!pip install missingno
import missingno as msno

msno.matrix(df_filtered)

df_filtered.info()

df_nulls = df.copy()
for col in df_nulls:
    if df_nulls[col].isna().sum() == 0:
        del df_nulls[col]
df_nulls

"""### Missing matrix

"""

df.info()

#No Missing Values found

import pickle
with open('income.pkl', 'wb') as f:
    pickle.dump(df_filtered, f)

print("incomes_df2 saved as a pickle file.")

